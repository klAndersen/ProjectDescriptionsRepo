%\section{section5}
\label{sec:section5}

\subsection[Global Software Development]{\getprefix{imt4112}}
\label{sec:glob_soft_dev}
% space for readability
\begin{itemize} 
	\item \getprefix{level}: \getprefix{master}
	\item \getprefix{type}: \getprefix{group}, \getprefix{ass}
	\item \getprefix{college}: \getprefix{ntnu}
	\item \getprefix{ide}: \getprefix{pycharm}, \getprefix{al}, VirtualBox, OpenEdX\footnote{\url{https://open.edx.org/}}, XBlocks\footnote{\url{https://open.edx.org/xblocks}}, 
	\getprefix{git}, \getprefix{gith}, \getprefix{scrum}
	\item \getprefix{progLang}: \getprefix{py}, \getprefix{html}, \getprefix{js}
\end{itemize} 
% space for readability
\paragraph{Project background} ~\\
OpenEdX is a community driven, open, open-source development and delivery platform for online courses and MOOCs. 
The codebase is hosted on GitHub under the edx-platform repository, and managed by the EdX consortium.  
There is a native Android client and iOS app codebase hosted on GitHub too. 
The project offers comprehensive learning management system tools and authoring for lecturers, allows uploading the lecture videos, lecture slides, 
audio and preparing written course material in a form of handouts. 
There is a number of built-in modules for various in-class tasks.

\paragraph{Project goals} ~\\
The goals of the project are three-fold:
\begin{enumerate}
	\item to understand and gain in-depth knowledge about the platform, architecture, and organization of the existing codebase
	\item to understand the process, requirements, and compliance when contributing to a (large) open source project
	\item to be able to contribute to an open-source project
\end{enumerate}

\paragraph{Task 1} ~\\
Multi-choice questionnaire with confidence level attached to each individual questions that changes the marking of that question. 
We will follow a 3-levels-of-confidence model, in which the following is the scoring matrix for appropriate confidence levels 
(the "+1" means: "student gets 1 point for correctly answering this question"):
% table listing the confidence level with scores based on correct/wrong answer
\begin{center}
	\begin{tabular}{ | l | l | l | p{5cm} |} \hline 		
		confidence 	& correct answer 	& wrong answer  \\ \hline
		0 - low 	& +1 				& 0  			\\ \hline
		1 - normal 	& +1.5 				& -0.5  		\\ \hline
		2 - high 	& +2 				& -1  			\\ \hline
	\end{tabular}
\end{center}
% space for readability
In this task, the parts I worked on was the creation of answer alternatives, the answers submitted by the students and and grade for the submitted questionnaires (with confidence level).

\paragraph{Task 2} ~\\
Short-answer or multi choice questionnaire that allows students to annotate questions with two values: 
"for all students in this class, this question is harder then average" or "easier than average". 
This should allow the students to reflect on the knowledge of their peers and to judge the level of confidence of their peers. 
This point can be extended by calculating the scores for people that got more of the annotation correct as calculated against the actual test results 
for this particular question in this test.
\vspace{0.5em}\newline
Here I worked on the part related to difficulty level, and updating the students score.

\subsection[Advanced Project Work]{\getprefix{imt5251}}
\label{sec:adv_proj_work}
% space for readability
\begin{itemize} 
	\item \getprefix{level}: \getprefix{master}
	\item \getprefix{college}: \getprefix{ntnu}
	\item \getprefix{ide}: \getprefix{pycharm}, \getprefix{mysqlw}, \getprefix{al}, \getprefix{git}, \getprefix{gith}, 
	Py-StackExchange\footnote{\url{https://github.com/lucjon/Py-StackExchange}}
	\item \getprefix{progLang}: \getprefix{py2}, \getprefix{html}, Django, XBlocks
	\item \getprefix{ghrepo} \url{https://github.com/klAndersen/IMT5251_AdvProjWork}
\end{itemize} 
% space for readability
% TODO: Re-view and re-write this
Preliminary work for my Master thesis, which was mostly focused on creating a simplistic prototype. 
The topic for my Master thesis was to develop a Chat Agent that could answer students programming questions,  and also help them learn to be better at asking good questions. 
The Chat Agent was to be implemented as a module (an XBlock) in the Learning Management System (LMS) Open edx. 
\vspace{0.5em}\newline
During this development, a simple chat interface was created which could connect to StackOverflow.com. 
One could ask questions, but it only returned the first question/answer it found on Stack Overflow. 
The prototype was also presented to two students that gave feedback and suggestions for features. 
The plan for further development was to implement AI in my Master thesis using a hybrid algorithm of Hidden-Markov-Model and Bayes Net. 

\subsection{Master thesis: Predicting coding question quality}
\label{sec:master_thesis}
% space for readability
\begin{itemize} 
	\item \getprefix{level}: \getprefix{master}
	\item \getprefix{college}: \getprefix{ntnu}
	\item \getprefix{course}: \getprefix{imt4904}
	\item \getprefix{ide}: \getprefix{pycharm}, \getprefix{mysqlw}, \getprefix{al}, \getprefix{git}, \getprefix{gith}
	\item \getprefix{progLang}: \getprefix{py2}, \getprefix{py3} (submitted version)
	\item Code \getprefix{ghrepo} \url{https://github.com/klAndersen/IMT4904_MasterThesis_Code}
	\item Thesis \getprefix{ghrepo} \url{https://github.com/klAndersen/IMT4904_MasterThesis_LaTex/}
\end{itemize} 
% space for readability
During the presentation of the thesis topic, I was told that my topic was not just too large for a Master thesis, but even too large for a Ph.d. thesis. 
It therefore needed to be reduced drastically, which ended up with the topic being: "Predicting coding question quality using Stack Overflow ratings". 

\paragraph{Problem description} ~\\
Most of the systems that have been developed so far focuses on finding the best answer to a question asked by the user. 
Few, if any, focuses on the quality of the question being asked. 
What defines a good question, and can we in anyway predict whether or not a new question posted on \getprefix{so} will be considered good or bad by the community?
There are many users who has either a negative view or relationship in regards to \getprefix{so}.
Many experience that their questions gets down-voted, closed or even deleted. 
For some, they simply do not know how to ask an acceptable question.
Questions related to homework are one example of questions that are not accepted on \getprefix{so}.
There is even a post on Meta.StackExchange discussing whether or not it should be acceptable to use greetings and sentiments in posts\footnote{
	\url{http://meta.stackexchange.com/questions/2950/should-hi-thanks-taglines-and-salutations-be-removed-from-posts}
}.
Therefore, the question becomes: What is and is not a valid question on \getprefix{so}?

\paragraph{Research questions}
\begin{itemize}
	\item What defines a good (coding) question on \getprefix{so}?
	\item Can we predict a questions quality by using Support Vector Machines (SVM)?
	\item What type of features increases the accuracy of the SVM?
\end{itemize}

\paragraph{Development process} ~\\
The data used in the thesis was downloaded from StackExchange Archive\footnote{\url{https://archive.org/details/stackexchange}}, and inserted into a MySQL database, 
where the tables were based on the files available.
Data was extracted from the database into Python using a library called pandas\footnote{\url{http://pandas.pydata.org/}}, which also had the ability to export the data to a CSV file. 
The questions were originally in HTML format, so they were therefore cleansed using Beautiful Soup 4\footnote{
	\url{https://www.crummy.com/software/BeautifulSoup/bs4/doc/}
} (bs4). 
To get the vocabulary over all the words used in all the selected questions, CountVectorizer from the Machine learning library scikit-learn\footnote{
	\url{http://scikit-learn.org/stable/}
} was used. 
Features were extracted and replaced with feature detectors, and these were then used to create a model for predicting the question quality. 
